{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Emotions Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything with data, we need to import the necessary libraries to read and manipulate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nirvana</td>\n",
       "      <td>Rock</td>\n",
       "      <td>You Know You’re Right</td>\n",
       "      <td>Nirvana</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>I will never bother you\\nI will never promise ...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damian Marley</td>\n",
       "      <td>Reggae</td>\n",
       "      <td>Here We Go</td>\n",
       "      <td>Stony Hill</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Here we go\\nMy big ego is gonna get me in trou...</td>\n",
       "      <td>Tension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Mission UK</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Jade</td>\n",
       "      <td>Another Fall from Grace</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>She came as Lolita dressed as Venus\\nAnd adorn...</td>\n",
       "      <td>Tenderness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UB40</td>\n",
       "      <td>Reggae</td>\n",
       "      <td>Food For Thought</td>\n",
       "      <td>Signing Off</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Ivory Madonna, dying in the dust\\nWaiting for ...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny Cash</td>\n",
       "      <td>Country</td>\n",
       "      <td>I’ve Been Everywhere</td>\n",
       "      <td>American II: Unchained</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>I was totin' my pack along the dusty Winnemucc...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    genre                  title                    album  \\\n",
       "0         Nirvana     Rock  You Know You’re Right                  Nirvana   \n",
       "1   Damian Marley   Reggae             Here We Go               Stony Hill   \n",
       "2  The Mission UK     Rock                   Jade  Another Fall from Grace   \n",
       "3            UB40   Reggae       Food For Thought              Signing Off   \n",
       "4     Johnny Cash  Country   I’ve Been Everywhere   American II: Unchained   \n",
       "\n",
       "     year                                             lyrics       label  \n",
       "0  2002.0  I will never bother you\\nI will never promise ...     Sadness  \n",
       "1  2017.0  Here we go\\nMy big ego is gonna get me in trou...     Tension  \n",
       "2  2016.0  She came as Lolita dressed as Venus\\nAnd adorn...  Tenderness  \n",
       "3  1980.0  Ivory Madonna, dying in the dust\\nWaiting for ...     Sadness  \n",
       "4  1996.0  I was totin' my pack along the dusty Winnemucc...     Sadness  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_label = pd.read_csv('SingleLabel.csv', encoding='utf-8')\n",
    "single_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataset contains several headers that give us information on the collected songs, such as the artist, genre, title, etc. The final column, \"label\", along with the \"lyrics\" column is to be used for the Classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nirvana</td>\n",
       "      <td>Rock</td>\n",
       "      <td>You Know You’re Right</td>\n",
       "      <td>Nirvana</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>I will never bother you\\nI will never promise ...</td>\n",
       "      <td>Calmness, Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damian Marley</td>\n",
       "      <td>Reggae</td>\n",
       "      <td>Here We Go</td>\n",
       "      <td>Stony Hill</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Here we go\\nMy big ego is gonna get me in trou...</td>\n",
       "      <td>Power, Tension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Mission UK</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Jade</td>\n",
       "      <td>Another Fall from Grace</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>She came as Lolita dressed as Venus\\nAnd adorn...</td>\n",
       "      <td>Amazement, Calmness, Solemnity, Tenderness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UB40</td>\n",
       "      <td>Reggae</td>\n",
       "      <td>Food For Thought</td>\n",
       "      <td>Signing Off</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Ivory Madonna, dying in the dust\\nWaiting for ...</td>\n",
       "      <td>Joyful activation, Sadness, Tension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny Cash</td>\n",
       "      <td>Country</td>\n",
       "      <td>I’ve Been Everywhere</td>\n",
       "      <td>American II: Unchained</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>I was totin' my pack along the dusty Winnemucc...</td>\n",
       "      <td>Amazement, Calmness, Joyful activation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    genre                  title                    album  \\\n",
       "0         Nirvana     Rock  You Know You’re Right                  Nirvana   \n",
       "1   Damian Marley   Reggae             Here We Go               Stony Hill   \n",
       "2  The Mission UK     Rock                   Jade  Another Fall from Grace   \n",
       "3            UB40   Reggae       Food For Thought              Signing Off   \n",
       "4     Johnny Cash  Country   I’ve Been Everywhere   American II: Unchained   \n",
       "\n",
       "     year                                             lyrics  \\\n",
       "0  2002.0  I will never bother you\\nI will never promise ...   \n",
       "1  2017.0  Here we go\\nMy big ego is gonna get me in trou...   \n",
       "2  2016.0  She came as Lolita dressed as Venus\\nAnd adorn...   \n",
       "3  1980.0  Ivory Madonna, dying in the dust\\nWaiting for ...   \n",
       "4  1996.0  I was totin' my pack along the dusty Winnemucc...   \n",
       "\n",
       "                                       labels  \n",
       "0                           Calmness, Sadness  \n",
       "1                              Power, Tension  \n",
       "2  Amazement, Calmness, Solemnity, Tenderness  \n",
       "3         Joyful activation, Sadness, Tension  \n",
       "4      Amazement, Calmness, Joyful activation  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label = pd.read_csv('MultiLabel.csv', encoding='utf-8')\n",
    "multi_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains the same information but differs in the final column, with it being labels and containing multiple labels for each example. This dataset is to be used for the Multi-Label Classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the classes distribution, before transforming the data to model-interpretable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sadness       569\n",
       "Tenderness    326\n",
       "Tension       265\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_label['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadness is the most represented class, with Tenderness and Tension following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the neccessary libraries, we split the data in X and y (the \"lyrics\" data and the \"label\" data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I will never bother you\\nI will never promise ...\n",
       "1    Here we go\\nMy big ego is gonna get me in trou...\n",
       "2    She came as Lolita dressed as Venus\\nAnd adorn...\n",
       "3    Ivory Madonna, dying in the dust\\nWaiting for ...\n",
       "4    I was totin' my pack along the dusty Winnemucc...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = single_label['lyrics']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sadness\n",
       "1       Tension\n",
       "2    Tenderness\n",
       "3       Sadness\n",
       "4       Sadness\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = single_label['label']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up a TF/IDF Vectorizer to transform our lyrics into features that indicate their belonging to one of the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors=[]\n",
    "type={\n",
    "    1:'unigram',\n",
    "    2:'bigram',\n",
    "    3:'trigram'\n",
    "}\n",
    "for i in range(1,4):\n",
    "    for j in range(i,4):\n",
    "        tfidf_vectors.append((type[i],type[j],TfidfVectorizer(min_df=3, max_features=3000, strip_accents='unicode',lowercase =True,\n",
    "                            analyzer='word', token_pattern=r'\\w{3,}', ngram_range=(i,j),\n",
    "                            use_idf=True,smooth_idf=True, sublinear_tf=True, stop_words = \"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define our classifier as a LinearSVC and create a pipeline that first transforms the data and then feeds it into the Machine Learning classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_result(tfv, model,y_test):\n",
    "    pipeline = make_pipeline(tfv, model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return accuracy_score(pipeline.predict(X_test),y_test)\n",
    "\n",
    "def linear_svc(tfv,X_train,X_test,y_train,y_test):\n",
    "    clf = LinearSVC(random_state=0)\n",
    "    return get_pipeline_result(tfv, clf,y_test)\n",
    "\n",
    "def rbf_svc(tfv,X_train,X_test,y_train,y_test):\n",
    "    clf = SVC(kernel='rbf',gamma='scale')\n",
    "    return get_pipeline_result(tfv, clf,y_test)\n",
    "\n",
    "def knn(tfv,X_train,X_test,y_train,y_test,n):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n)\n",
    "    return get_pipeline_result(tfv,knn_classifier,y_test)\n",
    "\n",
    "def random_forest(tfv,X_train,X_test,y_train,y_test):\n",
    "    rf = RandomForestClassifier(random_state=0,n_estimators = 100)\n",
    "    return get_pipeline_result(tfv, rf,y_test)\n",
    "\n",
    "def decision_tree(tfv,X_train,X_test,y_train,y_test):\n",
    "    dt = DecisionTreeClassifier()\n",
    "    return get_pipeline_result(tfv, dt,y_test)\n",
    "\n",
    "def mlp_classifier(tfv,X_train,X_test,y_train,y_test,active_func=None):\n",
    "    mlp = MLPClassifier(max_iter=1000,activation=active_func)\n",
    "    return get_pipeline_result(tfv, mlp,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tu + u\tu + b\tu + t\tb + b\tb + t\tt + t\t\n",
      "SVC-L\t61.03\t60.69\t60.34\t53.45\t52.76\t50.69\t\n",
      "SVC-R\t61.72\t61.03\t61.03\t54.48\t53.79\t50.0\t\n",
      "RF\t61.03\t62.41\t60.0\t55.86\t54.14\t50.0\t\n",
      "DT\t51.03\t51.79\t49.34\t48.93\t49.34\t50.24\t\n",
      "KNN-3\t54.48\t53.79\t53.45\t51.03\t51.03\t50.34\t\n",
      "KNN-4\t50.69\t55.52\t53.45\t43.1\t42.41\t49.66\t\n",
      "KNN-5\t51.72\t54.14\t53.79\t45.17\t44.14\t50.69\t\n",
      "KNN-6\t53.1\t55.17\t56.55\t44.48\t44.83\t50.0\t\n",
      "KNN-7\t53.79\t54.83\t54.48\t45.52\t43.45\t52.76\t\n",
      "KNN-8\t54.14\t56.9\t56.9\t48.62\t43.45\t52.07\t\n",
      "KNN-9\t53.79\t58.28\t57.93\t48.28\t47.59\t52.76\t\n",
      "MLP-l\t60.14\t56.66\t55.79\t52.14\t52.1\t50.31\t\n",
      "MLP-r\t59.41\t57.59\t55.83\t52.83\t51.66\t50.1\t\n",
      "MLP-t\t59.62\t56.62\t55.66\t52.59\t52.21\t50.31\t\n"
     ]
    }
   ],
   "source": [
    "activations = ['logistic','relu','tanh']\n",
    "overall_result = {\n",
    "    'SVC-L':{},\n",
    "    'SVC-R':{},\n",
    "    'RF':{},\n",
    "    'DT':{}\n",
    "}\n",
    "for i in range(3,10):\n",
    "        overall_result['KNN-'+str(i)]={}\n",
    "for activation in activations:\n",
    "    overall_result['MLP-'+activation[0]]={}\n",
    "bow = ['u + u', 'u + b','u + t','b + b','b + t','t + t']\n",
    "\n",
    "for tfv_count in range(len(tfidf_vectors)):\n",
    "    tfv = tfidf_vectors[tfv_count][2]\n",
    "    results = {\n",
    "        'SVC-L':[],\n",
    "        'SVC-R':[],\n",
    "        'RF':[],\n",
    "        'DT':[]\n",
    "    }\n",
    "    for i in range(3,10):\n",
    "        results['KNN-'+str(i)]=[]\n",
    "    for activation in activations:\n",
    "        results['MLP-'+activation[0]]=[]\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)\n",
    "        results['SVC-L'].append(linear_svc(tfv,X_train, X_test, y_train,y_test))\n",
    "        results['SVC-R'].append(rbf_svc(tfv,X_train, X_test, y_train,y_test))\n",
    "        for i in range(3,10):\n",
    "            results['KNN-'+str(i)].append(knn(tfv,X_train, X_test, y_train,y_test,i))\n",
    "        results['RF'].append(random_forest(tfv,X_train, X_test, y_train,y_test))\n",
    "        results['DT'].append(decision_tree(tfv,X_train, X_test, y_train,y_test))\n",
    "        for activation in activations:\n",
    "            results['MLP-'+activation[0]].append(mlp_classifier(tfv,X_train, X_test, y_train,y_test,activation))\n",
    "    for result in results:\n",
    "        overall_result[result][tfidf_vectors[tfv_count][0][0]+' + '+tfidf_vectors[tfv_count][1][0]]=round(mean(results[result])*100,2)\n",
    "        \n",
    "print('Model\\t',end='')\n",
    "for name in bow:\n",
    "    print(name+'\\t',sep='',end='')\n",
    "print('')\n",
    "for model in overall_result:\n",
    "    print(model+'\\t',sep='',end='')\n",
    "    for name in bow:\n",
    "        print(str(overall_result[model][name])+'\\t',sep='',end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to take a look at the distribution of labels in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(', '))\n",
    "emotion_dtm = vectorizer.fit_transform(multi_label['labels'])\n",
    "print('Number of data points:', emotion_dtm.shape[0])\n",
    "print('Number of unique emotions:', emotion_dtm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = vectorizer.get_feature_names()\n",
    "freqs = emotion_dtm.sum(axis=0).A1\n",
    "result = dict(zip(emotions, freqs))\n",
    "print(result.items())\n",
    "freq_count = pd.DataFrame(list(result.items()), columns=['Emotions', 'Counts'])\n",
    "freq_sorted = freq_count.sort_values(['Counts'], ascending=False)\n",
    "freq_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_per_example = emotion_dtm.sum(axis=1).tolist()\n",
    "emotion_per_example = [int(j) for i in emotion_per_example for j in i]\n",
    "print('Maximum emotions per example: %d'%max(emotion_per_example))\n",
    "print('Minimum emotions per example: %d'%min(emotion_per_example))\n",
    "print('Average emotions per example: %f'% ((sum(emotion_per_example))/len(emotion_per_example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a closer look at the data in hand, we proceed with solving the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we will need a Binarizer for the labels. As each example is annotated as more than one classes, we need to transform this information to a machine-readable format. But first, let's create X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = multi_label['lyrics']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(multi_label['labels'])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the line above, our labels are transformed into arrays, where 1 indicates the presence of a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem we are using Logistic Regression-trained classifiers for each class, with the help of the OneVsRestClassifier. The data is again fed into the classifier via a pipeline, where it is transformed into vectors of TF/IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "clf = OneVsRestClassifier(lr)\n",
    "pipeline = make_pipeline(tfv, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our model, we once again split into training and test sets to calculate our classifier's efficiency in classifying lyrics into sets of emotions' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit our classifiers, we import the f1-score metric to evaluate the efficiency of learning of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the average setting of f1_score is set to micro in order to aggregate the contributions of all classes and compute the average metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print('F1-SCORE :',f1_score(y_test, y_pred, average=\"micro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
